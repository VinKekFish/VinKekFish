# Этот файл использовался для разработки, но не описывает окончательный вариант VinKekFish
# Его не нужно читать для того, чтобы понять, как он устроен

Интуитивно размышляем насчёт алгоритма с повышенной длиной ключа

1. Чтобы построить расширенный алгоритм, желательно обеспечить
	Многопоточность
	Возможность блоков эффективно обмениваться друг с другом информацией
	Некоторая доп. стойкость
	Вопрос насчёт использования большого объёма памяти со случайным доступом остаётся открытым

Вероятность атаки на губку равна вероятности успешной атаки на случайный оракул плюс N*N/2^(c-1), где с - ёмкость (внутреннее состояние) губки, N - количество запросов к губке.
Например, для запросов 2^(c/2) будет 2^c/2^(c-1).
Для заданной вероятности x битов будет 1/2^x = N*N/2^(c-1) => 2^(c-1)/2^x = N*N => N = 2^((c-1)/(x/2))
N = 2^((c-1)/(x/2))


Обмен блоков информацией
	Интуитивно, каждый блок должен обмениваться с каждым, то есть квадратичная сложность.
	Если каждый блок представить алгоритмом keccak, то можно было бы сказать, что keccak должен передать входной блок каждому другому блоку, а тот должен этот блок принять
	Пусть у нас везде нули и только на одном блоке установлен один бит. Этот бит должен распространиться, причём дав разные фрагменты общего состояния. Это касается даже случаев, когда мы явно обеспечиваем отсутствие такой ситуации (где всё - нули)
	Как знать, что этот бит не будет "поглощён" другими битами. С одной стороны, бит, наверное, будет и через многократные преобразования влиять на каждый бит результата. С другой стороны, при многократных преобразованиях можно интуитивно считать, что биты "поглощаются". Так, если взять совсем простой хеш и многократно его прохешировать, когда-то он случайно придёт к первоначальному состоянию. Правда, когда именно - это тоже случайность. Длина этой цепочки - тоже информация.
	Если бит влияет на другой бит с вероятностью 1/2, то это значит, вероятность того, что этот бит не повлиял ни на какой другой составляет 1/2^n. То есть для n битов будет потеряно n/2^n битов. Для 16 битов это будет 16/2^16=1/4096. Для 32 битов это будет 32/2^32=1/134217728.
	Приблизительно, можно считать, что для L шагов преобразований, будет потеряно L*n/2^n.
	Таким образом, L*n должно быть существенно меньше, чем 2^n. Оно всегда так.
	Для входа в 2*n битов можно считать, что биты на выходе n битов представлены с вероятностью 1/2.
	Значит, для n преобразований вероятность будет 1/2^n, то есть для уверенного распространения бита нужно будет повторить цепочку операций 2^n раз (каждый раз с новой подачей этого бита в цепочку операций).
	Либо подать в каждый из n блоков бит данных напрямую один раз.
	
	Из губочных статей следует, что примерная потеря энтропии равна N*N/2^c, где c - ёмкость, N - количество вызовов функции.

Скрытые блоки
	Теоретически, анализ информации можно затруднить.
	Предположим, что обращение данных для хеша возможно и идёт длительно, но приемлемо. Для обращения внутреннего состояния нам нужно, допустим, 3 хеша (состояние keccak 200 байтов, за три хеша мы получим 196).
	Если мы возьмём два блока, 1 -> 2 -> 1 -> выход, то чтобы обратить данные, то у нас получается внутреннее состояние уже двойное (такая набла: спуск-подъём). Чтобы обратить выход нам нужно с блока 1 получить два хеша подряд. Но хеши мы получаем не подряд, то есть уже сложность.
	Таким образом, нам нужно всегда при генерации не просто генерировать хеш, но либо использовать скрытый блок 1 -> 2 -> 1 -> выход, либо использовать водопад 1 -> 2 -> выход.
	Теоретически, можно представить себе 1 -> 2 + (второй вход -> 2) -> 1 -> выход.
	Сначала спускаем информацию вниз, потом она назад всплывает вверх, но с дополнительной рандомизацией.
	
	
Перестановки
	Во внутреннем блоке могут быть перестановки байтов.
	То есть мы доверяем исходному преобразованию, но делаем перестановки байтов. Таким образом, мы доставляем все байты во все блоки.
	Возможно, это означает, что у нас должно быть два внутренних состояния: одно управляет перемешиванием, а второе перемешивается. А потом они меняются местами.
	Проблема в том, что перемешивать надо много, а состояния мало.
	Либо надо брать хеш от состояния и перемешивать от этого хеша.
	Либо от самого состояния всё брать, что нужно
	
	Перестановки могут быть уязвимы к ПЭМИН, ведь перестановка данных не из кеша может выглядеть не очень: дополнительный всплеск вычислений на времена порядка 1/72 периода, то есть для 2,8 ГГц это 38 МГц.
	Впрочем, если считать кеш 32 кб, то это уже много для 16 кб состояния. Может и ничего

	Как делать псевдопреобразование тройками?
	M = 
		1 3 5
		5 1 3
		3 5 1

	// Обратная матрица https://ru.onlinemschool.com/math/assistance/matrix/inverse/
	всё делить на 54
	-7 11  2
	 2 -7 11
	11  2 -7

	При переполнении нужно добавлять, в идеале, переполненные результаты куда-нибудь
	Можно перемешивать семёрками байтов. Но это проблема. Делить на 7 нацело внутреннее состояние не получится.
	В любом случае, теряются биты, похоже что. То есть без гарантий

	Либо, всё-таки, пользоваться классическим преобразованием адамара

	256*8 байтов внутреннего состояния, то есть 2048 байтов, то есть 16384 битов
	Можно переставлять тройками, смотря каждый байт. Всего получится 682 перестановки элементов по 8-мь байтов
	8-мибайтовые слова можно ещё и ротировать дополнительно. Например, если они ставятся на индекс i, то их можно ротировать вправо на (i % 31)
	
	Сдвиг переставляемого слова ещё и может быть в пределах 8-ми байтов. То есть можно брать какую-то константу, например, сумму от переставляемых слов, и брать из неё три бита для сдвига.


	Из-за того, что кеширование может повлиять на атаки по побочным каналам, возможно, не стоит вообще пользоваться какими-либо перестановками, зависящими от ключа. То есть перестановки должны быть только общие для всех ключей, а потом должен применяться обычный keccak и treefish.
	См. спецификацию Skein 
	
	1. После каждого раунда шифрования можно делать перемешивание по таблицам. Таблицы чередовать с разными способами получения: перемешивание предсказуемым алгоритмом, перемешивание заранее сделанным псевдослучайным алгоритмом, перемешивание на основе tweak (синхропосылки или "настройки"). Но tweak при подготовке может быть опасен для тайминг-атак.
		При перемешивании можно перемешивать дважды.
			Первое перемешивание: по 8-байтовым словам со сдвигом.
			Второе перемешивание: по байтам со сдвигом.
			Возможно, третье перемешивание: по два индекса на их местах: преобразование адамара. А может, нефиг баловаться?
			При перемешивании также может накладываться битовая маска xor, однако это большой вопрос (маска может вычисляться keccak)
	2. Применение полнораундового keccak
	3. Применение полнораундового treefish. При этом это тоже таблица: индекс для tweak, индекс для key (в старом состоянии, результат записывается в новое состояние; или, всё-таки делается всё на новом состоянии?).
	4. Снова перемешивание. В конце - взять каждый четвёртый элемент внутреннего состояния
	5. Возможно, для каждого блока по 64-байта поставить его в свой keccak для дополнительной защиты


Ещё раз
	keccak первый для рандомизации как можно большего числа байт.
	
	1. Однопоточный вариант со сцеплением.
		keccak применяются последовательно со сцеплением между блоками.
		Сцепление между блоками можно сделать на 14 байтов. Тогда, на 10 блоках будет 200*10-14*10=1860.
		2048-1860=188. Сцепление на последнем, 11-ом блоке, будет 12 байтов.

	2. Предлагается многопоточный вариант.
	Создаётся 16 потоков.
		2.1. 10 потоков применяют keccak к состоянию. Каждый поток также копирует свои 200 байтов в копию состояния.
		2.2. 8 потоков применяют keccak к состоянию, оставляя промежутки между блоками
			Потом смещаются на эти промежутки и применяют keccak уже к ним

	В принципе, многопоточный вариант даже интереснее будет. Особенно, если учесть, что гаммирование с обратной связью будет в 8-мь раз быстрее тогда.

	С другой стороны, нахлёст keccak больше, чем на 8-мь байтов может быть чреват какими-то побочными эффектами на криптостойкость.
	В крайнем случае, спец. аппаратура получат прирост производительности в 8-мь раз по сравнению с компьютером, если всё делать без нахлёста (без сцепления).
	
	Что лучше?
	1. Производительность многопоточного варианта, в целом, обещает быть лучше.
		Это можно преднамеренно компенсировать более мощным шифрованием с каскадом (то есть большое количество ядер просто будут увеличивать каскад, повышая общую стойкость шифрования).
	2. 

	Кстати, если взять 25600 битов (3200 байтов) состояния, то они делятся на цело: 3200/200=16, 3200/128=25
	Вход должен быть, в идеале, целым блоком. Это 4096 битов. Тогда и выход должен быть таким же (512 байтов).
	4096/512=8. Нужно, чтобы полное состояние было известно злоумышленнику только после 8-микратного обращения алгоритмов. То есть 25600/4=6400 должно быть известно не менее, чем через 8-мь шагов.
	6400/8=800 байтов. То есть по 100 байтов на каждый шаг. Это слишком мало, в общем-то.
	
	Если считать, что за один раунд обмен идёт примерно между 1 блоком из 16-ти (либо 1/16 блока), то получим, что полный обмен идёт за 16 раундов.
	Если мне нужно 512 байтов за шаг, то нужно обеспечить многократное применение алгоритмов сразу в одном шаге. 800 байтов внешнего состояния должно стать известно не менее, чем за 8*16 раундов.
	А значит, 512/800*8*16=82. Нужно 82 раунда на всякий случай. Ну это с потолка в худшем случае.
	В лучшем случае можно сказать, что раундов должно быть 8 на рандомизацию, 16 на полное применение, +8 ещё на обеспечение криптостойкости.


Каскадные алгоритмы
	Атака встречи по середине (она же - двусторонняя атака)
	
	Описание классического алгоритма встречи по середине.

	Допустим, базовый алгоритм ThreeFish. Двойное шифрование S = E(k2, E(k1, p)).
	S и p известны злоумышленнику.
	Применим D(i2, S) = D(i2, E(k2, E(k1, p)))
	
	Если i2 = k2, то, очевидно, D(k2, S) = D(k2, E(k2, E(k1, p))), а значит
	D(k2, S) = E(k1, p)
	
	Получаем, что справедливо. D(i2, S) = E(i1, p). Таким образом, нам надо найти все i2, которые дают совпадения хотя бы с одним i1.
	Считая, что мы можем предвычислить E(i1, p) для всех i1, мы способны упростить атаку до перебора i2 с "мгновенным" поиском в таблице E(i1, p). Далее, все ложные совпадения перебираются на контрольной паре S2, p2.
	

	Для алгоритма keccak, считая отсутствие обратной функции
		S = E(k2, E(k1, p))
		D(i2, S) = D(i2, E(k2, E(k1, p)))
		Где D теперь функция, которая даёт все возможные варианты, в которых при ключе i2 при хешировании получилось бы S.

		Нужно вычислить такие i1, i2, что S = E(i2, E(i1, p))
		При отсутствии функции расшифрования получаем вычисление сводится к полному перебору вариантов, т.к. даже если мы вычислим все E(i2), то при проверке нам придётся проверять ещё и i3, то есть проверять все сочетания так или иначе

	Как сделать простую интуитивную модель, которая иллюстрирует стойкость keccak при введении более длинного ключа? И вообще, как понять его стойкость?
		
	И что делать с малым размером блока? Можно ли выжимать губку несколько раз подряд, чтобы получить один большой блок, а потом несколько раз подряд впитывать без выжимания?
